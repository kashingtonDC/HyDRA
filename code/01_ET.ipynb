{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import datetime\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import rsfuncs as rs\n",
    "\n",
    "import scipy.interpolate as interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "def dict2arr(data_dict, var_name):\n",
    "    '''converts ee dictionary output from .getInfo() to a numpy array. Wraps array_from_df'''\n",
    "    \n",
    "    data = data_dict[var_name]\n",
    "    lats = data_dict['latitude']\n",
    "    lons = data_dict['longitude']\n",
    "\n",
    "    df = pd.DataFrame([data,lats,lons]).T\n",
    "    df.columns = [var_name, \"latitude\", 'longitude']\n",
    "    arr = rs.array_from_df(df, var_name)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def map_cdl2fmp(dictionary,array):\n",
    "    '''maps values on cdl image to the fmp'''\n",
    "    \n",
    "    mapping = dictionary.copy()\n",
    "    \n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "\n",
    "    for k,v in mapping.items():\n",
    "        for i in v:\n",
    "            if i == \"\":\n",
    "                continue\n",
    "            else:\n",
    "                vec1.append(int(i))\n",
    "                vec2.append(int(k))\n",
    "                \n",
    "    out_im = np.zeros_like(array)\n",
    "    for k,v in dict(zip(vec1,vec2)).items():\n",
    "        out_im[array==k] =v\n",
    "    \n",
    "    return out_im\n",
    "\n",
    "\n",
    "def map_fmp2kc(dictionary,array):\n",
    "    '''maps values on fmp image to kc'''\n",
    "\n",
    "    mapping = dictionary.copy()\n",
    "    \n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "\n",
    "    for k,v in mapping.items():\n",
    "        vec1.append(k)\n",
    "        vec2.append(v)\n",
    "                \n",
    "    out_im = np.zeros_like(array)\n",
    "    for k,v in dict(zip(vec1,vec2)).items():\n",
    "        out_im[array==k] =v\n",
    "    \n",
    "    return out_im\n",
    "\n",
    "\n",
    "def get_monthly_et(dataset, start, end, aoi):\n",
    "    '''\n",
    "    Get gridded monthly ET sums from MODIS \n",
    "    '''\n",
    "\n",
    "    ImageCollection = dataset[0]\n",
    "    var = dataset[1]\n",
    "    scaling_factor = dataset[2]\n",
    "    resolution = dataset[3]\n",
    "\n",
    "    dt_idx = pd.date_range(start,end, freq='MS')\n",
    "    ims = []\n",
    "    seq = ee.List.sequence(0, len(dt_idx)-1)\n",
    "    num_steps = seq.getInfo()\n",
    "    \n",
    "    for i in num_steps[:]:\n",
    "\n",
    "        t1 = ee.Date(start).advance(i, 'month')\n",
    "        t2 = t1.advance(1, 'month');\n",
    "\n",
    "        im = ee.Image(ImageCollection.select(var).filterDate(t1, t2).sum().set('system:time_start', t1.millis()))\n",
    "        modis_dat = im.pixelLonLat().addBands(im).multiply(scaling_factor).reduceRegion(reducer=ee.Reducer.toList(),\n",
    "                                                               geometry=aoi,\n",
    "                                                               scale=1000, crs ='EPSG:4326')\n",
    "\n",
    "        modis_dict = modis_dat.getInfo()\n",
    "        modis_im = dict2arr(modis_dict, var)\n",
    "        ims.append(modis_im)\n",
    "\n",
    "    return ims\n",
    "\n",
    "def calc_monthly_sum(dataset, startdate, enddate, area):\n",
    "    '''\n",
    "    Calculates monthly sums (pd.Dataframe) for EE data given startdate, enddate, and area\n",
    "    Datasets are stored in `data` dict below.\n",
    "    Note the \"scaling_factor\" parameter, \n",
    "    which is provided by EE for each dataset, and further scaled by temporal resolution to achieve monthly resolution\n",
    "    This is explicitly written in the `data` dict \n",
    "    \n",
    "    EE will throw a cryptic error if the daterange you input is not valid for the product of interest, or if the AOI is e.g. in middle of ocean\n",
    "    '''\n",
    "\n",
    "    ImageCollection = dataset[0]\n",
    "    var = dataset[1]\n",
    "    scaling_factor = dataset[2]\n",
    "    resolution = dataset[3]\n",
    "    \n",
    "    dt_idx = pd.date_range(startdate,enddate, freq='MS')\n",
    "    sums = []\n",
    "    seq = ee.List.sequence(0, len(dt_idx)-1)\n",
    "    num_steps = seq.getInfo()\n",
    "\n",
    "    for i in num_steps:\n",
    "\n",
    "        start = ee.Date(startdate).advance(i, 'month')\n",
    "        end = start.advance(1, 'month');\n",
    "\n",
    "        im = ee.Image(ImageCollection.select(var).filterDate(start, end).sum().set('system:time_start', start.millis()))\n",
    "        scale = im.projection().nominalScale()\n",
    "        scaled_im = im.multiply(scaling_factor).multiply(ee.Image.pixelArea()).multiply(1e-12) # mm --> km^3\n",
    "        \n",
    "        sumdict  = scaled_im.reduceRegion(\n",
    "            reducer = ee.Reducer.sum(),\n",
    "            geometry = area,\n",
    "            scale = resolution,\n",
    "            bestEffort= True)\n",
    "\n",
    "        total = sumdict.getInfo()[var]\n",
    "        sums.append(total)\n",
    "        \n",
    "    sumdf = pd.DataFrame(np.array(sums), dt_idx)\n",
    "    sumdf.columns = [var]\n",
    "    df = sumdf.astype(float)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def resample_1km_30m(im_1km,im_30m):\n",
    "    '''\n",
    "    Interpolates 1 km modis data on to 30m landsat grid\n",
    "    '''\n",
    "    \n",
    "    W, H = im_1km.shape[:2]\n",
    "    new_W, new_H = im_30m.shape[:2]\n",
    "    xrange = lambda x: np.linspace(0, 1, x)\n",
    "\n",
    "    f = interp.interp2d(xrange(H), xrange(W), im_1km, kind=\"linear\")\n",
    "    new_arr = f(xrange(new_H), xrange(new_W))\n",
    "    \n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def interp_modis_nans(modis_image):\n",
    "    '''\n",
    "    interpolates nans in modis imagery. Doesn't work if a whole row/col at edge of image is all nans \n",
    "    '''\n",
    "\n",
    "    W, H = modis_image.shape[:2]\n",
    "\n",
    "    # Mask nans \n",
    "    array = np.ma.masked_invalid(modis_image)\n",
    "\n",
    "    # Make the outgrid \n",
    "    xi = np.linspace(0, H, H)\n",
    "    yi = np.linspace(0, W, W)\n",
    "    xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "    # xx, yy = np.meshgrid(new_W, new_H)\n",
    "    x1 = xx[~array.mask]\n",
    "    y1 = yy[~array.mask]\n",
    "    newarr = array[~array.mask]\n",
    "\n",
    "    new_arr = interp.griddata((x1, y1), newarr.ravel(), (xx, yy),method='linear')\n",
    "    \n",
    "    return new_arr\n",
    "\n",
    "def find_nearest_nlcd(yearint, yearlist = [2001, 2004, 2006, 2008, 2011, 2013, 2016]):\n",
    "    absolute_diff = lambda list_value : abs(list_value - yearint)\n",
    "    closest_value = min(yearlist, key=absolute_diff)\n",
    "    return closest_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files, make polygons\n",
    "kc = pd.read_csv('../data/fmp_kc_faunt.csv')\n",
    "gdf = gp.read_file(\"../shape/cv.shp\")\n",
    "data = rs.load_data()\n",
    "\n",
    "# Split cv into polygons\n",
    "area = rs.gdf_to_ee_poly(gdf.simplify(0.01))\n",
    "polys = rs.gen_polys(area, dx = 0.2, dy = 0.2)\n",
    "polydict = polys.getInfo()\n",
    "\n",
    "strstart = '2001-01-01'\n",
    "strend = '2019-12-31'\n",
    "\n",
    "startdate = datetime.datetime.strptime(strstart, \"%Y-%m-%d\")\n",
    "enddate = datetime.datetime.strptime(strend, \"%Y-%m-%d\")\n",
    "years = range(2001, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure each poly is a single geometry \n",
    "\n",
    "valid_polys = []\n",
    "\n",
    "for i in tqdm(polydict['features'][:]):\n",
    "    aoi = ee.Geometry.Polygon(i['geometry']['coordinates']).intersection(area)\n",
    "    pols = aoi.getInfo()['coordinates']\n",
    "    if len(pols) == 0:\n",
    "        continue\n",
    "    if len(pols) == 1:\n",
    "        valid_polys.append(ee.Geometry.Polygon(pols))\n",
    "    if len(pols) > 1:\n",
    "        for i in pols:\n",
    "#             print(i)\n",
    "            valid_polys.append(ee.Geometry.Polygon(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aoi= valid_polys[147]\n",
    "\n",
    "for y in tqdm(years[-1:]):\n",
    "    \n",
    "    # print year and nlcd col \n",
    "    print(y)\n",
    "    \n",
    "    yearstart = \"{}-01-01\".format(str(y))\n",
    "    yearend = \"{}-12-31\".format(str(y))\n",
    "\n",
    "    # Select the nlcd dataset (2001, 2004, 2006, 2008, 2011, 2014, 2016)\n",
    "    nearest_year_start = \"{}-01-01\".format(str(find_nearest_nlcd(y)))\n",
    "    nlcd_col = ee.ImageCollection('USGS/NLCD')\n",
    "    nlcd = nlcd_col.filterDate(ee.Date(nearest_year_start),  ee.Date(nearest_year_start).advance(1, 'years')).first()\n",
    "        \n",
    "    # Compile NLCD \n",
    "    nlcd_dat = ee.Image.pixelLonLat().addBands(nlcd).reduceRegion(reducer=ee.Reducer.toList(),geometry=aoi,scale=30)\n",
    "    nlcd_dict = nlcd_dat.getInfo()\n",
    "    \n",
    "    # get PET classes (11-water, 81-crops, 82-pasture), and make everything else AET \n",
    "    nlcd_im = dict2arr(nlcd_dict, 'landcover')\n",
    "    petmask = np.isin(nlcd_im, [11,81,82], invert = False).reshape(nlcd_im.shape).astype(int)\n",
    "    aetmask = np.isin(nlcd_im, [11,81,82], invert = True).reshape(nlcd_im.shape).astype(int)\n",
    "\n",
    "    # Select the correct or most recent CDL\n",
    "    if y < 2008:\n",
    "        cdl = ee.Image(\"USDA/NASS/CDL/2008\")\n",
    "    else:\n",
    "        cdl = ee.Image(\"USDA/NASS/CDL/{}\".format(str(y)))\n",
    "        \n",
    "    # Compile CDL\n",
    "    cdl_dat = ee.Image.pixelLonLat().addBands(cdl).reduceRegion(reducer=ee.Reducer.toList(),geometry=aoi,scale=30)\n",
    "    cdl_dict = cdl_dat.getInfo()\n",
    "\n",
    "    # Make the ims \n",
    "    cdl_im = dict2arr(cdl_dict, 'cropland')\n",
    "\n",
    "    # Map values from the CDL to the FMP\n",
    "    mapping = rs.cdl_2_faunt()    \n",
    "    fmp_im = map_cdl2fmp(mapping, cdl_im)\n",
    "\n",
    "    # Map values from the FMP to kc (Schmid, 2004)\n",
    "    monthly_ims = []\n",
    "\n",
    "    for i in kc.columns[2:]:\n",
    "        kcvals = kc[i]\n",
    "        kckeys =kc[kc.columns[0]]\n",
    "        kcdict = dict(zip(kckeys, kcvals))\n",
    "        kc_im = map_fmp2kc(kcdict, fmp_im)\n",
    "        monthly_ims.append(kc_im)\n",
    "\n",
    "    aet = rs.calc_monthly_sum(data['modis_aet'],  yearstart,  yearend,  aoi)\n",
    "    pet = rs.calc_monthly_sum(data['modis_pet'], yearstart,  yearend, aoi)\n",
    "\n",
    "    aetims =  get_monthly_et(data['modis_aet'],  yearstart,  yearend, aoi = aoi) \n",
    "    petims = get_monthly_et(data['modis_pet'],  yearstart,  yearend, aoi = aoi)\n",
    "    \n",
    "    # Apply the kc method, convert mm to km = 1e-6; m^2 to km^2 = 1e-6; 900 m^2 / cell \n",
    "    sums = []\n",
    "    for aetim, petim ,kcim in zip(aetims, petims, monthly_ims):\n",
    "        tpet = np.nansum(resample_1km_30m(interp_modis_nans(petim), kcim)* kcim *petmask)* 1e-12 * 900\n",
    "        taet = np.nansum(resample_1km_30m(interp_modis_nans(aetim), kcim)* aetmask)*1e-12 * 900\n",
    "        sums.append(np.sum([tpet, taet]))\n",
    "\n",
    "    petsum = [np.nansum(x)*1e-9 * 900 for x in petims]\n",
    "    aetsum = [np.nansum(x)*1e-9 * 900 for x in aetims]\n",
    "        \n",
    "    ETdf = pd.DataFrame([sums]).T.set_index(pet.index) \n",
    "    ETdf.columns = ['ETkc']\n",
    "\n",
    "    ETdf['petsum'] = pet\n",
    "    ETdf['aetsum'] = aet\n",
    "    ETdf['aetimsum'] = aetsum\n",
    "    ETdf['petimsum'] = petsum\n",
    "    ETdf['kc_mean'] = np.array([np.mean(x) for x in monthly_ims])\n",
    "    ETdf['irr_frac'] = petmask.sum()/(petmask.sum() + aetmask.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sums, label = 'ETkc')\n",
    "plt.plot(petsum, label = 'PET')\n",
    "plt.plot(aetsum, label = 'AET')\n",
    "plt.plot(pet.values,label = 'PETraw')\n",
    "plt.plot(aet.values, label = 'AETraw')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pet.values*len(valid_polys), label = 'pet')\n",
    "plt.plot(aet.values*len(valid_polys),label = 'aet')\n",
    "plt.plot(np.array(sums)*len(valid_polys), label = 'sums')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pet.values*len(valid_polys))\n",
    "plt.plot(aet.values*len(valid_polys))\n",
    "plt.plot(np.array(sums)*len(valid_polys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
